pull(unique_id) |>
unique()
# create one vector with all the Ids that meet at one of the exclusion criteria
iat_exclusion <- c(iat_exclusion_incomplete_trial, iat_exclusion_short_rt, iat_exclusion_low_accuracy)
data_iat_without_practice_D_exclusions <-
data_iat_without_practice_D_score |>
mutate(exclude_iat = case_when(unique_id %in% iat_exclusion ~ "exclude",
TRUE ~ "include"))
data_processed <-
data_demographics_wide |>
full_join(data_bfi_reverse_scored_exclusion, by = "unique_id") |>
full_join(data_iat_without_practice_D_exclusions, by = "unique_id")
print(data_processed)
data_processed_master_exclude <- data_processed |>
mutate(
exclusion = case_when(exclude_not_between_1_and_6 == "exclude"~ "exclude",
exclude_incomplete_data == "exclude"  ~ "exclude",
exclude_iat == "exclude" ~ "exclude",
is.na(exclude_not_between_1_and_6) & is.na(exclude_incomplete_data) & is.na(exclude_iat) ~ "exclude",
TRUE ~ "include")
) |>
select(-c(exclude_not_between_1_and_6, exclude_incomplete_data, exclude_iat))
# in case this dir doesn't exist, create it
dir.create("../data/processed/")
# save data to disk in that dir
write_csv(data_processed_master_exclude, "../data/processed/data_processed.csv")
if(!file.exists("../data/processed/data_processed_codebook.xlsx")){
# convert the column names to a df
codebook_template <- data.frame(variable = colnames(data_processed_master_exclude)) |>
mutate(explanation = NA)
# write to disk as an excel file
write.xlsx(codebook_template, file = "../data/processed/data_processed_codebook.xlsx")
}
# set knit options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
library(ggdist)
library(ggrain)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
library(ggExtra)
library(patchwork)
library(ggrepel)
library(remotes)
library(ggmagnify)
library(report)
library(psych)
data_processed <- read_csv("../data/processed/data_processed.csv")
data_processed_after_exclusions <- data_processed |>
filter(exclusion == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
group_by(sex) |>
summarise(n = n()) |>
mutate(
sex = recode(sex, "f" = "female", "m" = "male"),
Percent = paste0(round_half_up((n / sum(n)) * 100, 1), "%")
) |>
rename(Sex = sex) |>
kable() |>
kable_classic(full_width = FALSE)
proportion_available_age <-
(sum(data_processed_after_exclusions$age != "other/missing/error") / nrow(data_processed_after_exclusions)) |>
round(3)
proportion_available_sex <-
(sum(data_processed_after_exclusions$sex %in% c("f", "m")) / nrow(data_processed_after_exclusions)) |>
round(3)
print(paste0("Variable age was available for ", proportion_available_age, " of participants and variable sex for ",
proportion_available_sex, " of participants."))
# defining a function to get all columns of one subscale in a vector
function_items_subscale_bfi <- function(subscale, n){
items_subscale_bfi <- c()
for (i in 1:n){
items_subscale_bfi <- append(items_subscale_bfi, paste0("bfi_", subscale, i))
}
items_subscale_bfi
}
# agreeableness
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("a", 9)), check.keys =TRUE)
# conscientiousness
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("c", 9)), check.keys =TRUE)
# extraversion
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("e", 8)), check.keys =TRUE)
# neuroticism
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("n", 8)), check.keys =TRUE)
# openness
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("o", 10)), check.keys =TRUE)
# defining a function for the histograms for the BFI subscales
histogram_bfi_subscales <- function(column, x_label){
ggplot(data_processed_after_exclusions, aes(x = get(column))) +
geom_histogram(binwidth = 0.1,
boundary = 0,
fill = viridis_pal(begin = 0.45, option = "mako")(1),
color = viridis_pal(begin = 0.30, option = "mako")(1)) +
xlab(x_label) +
ylab("Frequency") +
coord_cartesian(xlim = c(1,6))+
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 10))+
theme_minimal()
}
histogram_bfi_subscales("mean_bfi_a", "Mean Agreeableness")
histogram_bfi_subscales("mean_bfi_c", "Mean Conscientiousness")
histogram_bfi_subscales("mean_bfi_e", "Mean Extraversion")
histogram_bfi_subscales("mean_bfi_n", "Mean Neuroticism")
histogram_bfi_subscales("mean_bfi_o", "Mean Openness")
ggplot(data_processed_after_exclusions, aes(x = IAT_score)) +
geom_histogram(binwidth = 0.05,
boundary = 0,
fill = viridis_pal(begin = 0.45, option = "mako")(1),
color = viridis_pal(begin = 0.30, option = "mako")(1)) +
xlab("IAT Score") +
ylab("Frequency") +
coord_cartesian(xlim = c(-2,2))+
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 10))+
theme_minimal()
# making a new data frame with only the columnes required for the correlatio matrix
data_processed_cols_correlation <- data_processed |>
select(c(mean_bfi_a, mean_bfi_c, mean_bfi_e, mean_bfi_n, mean_bfi_o, IAT_score))
# making the correlation matrix
cor(data_processed_cols_correlation, use = "pairwise.complete.obs", method="pearson") |>
round(2)
# to run this test I'm creating a data frame with only the subjects that gave information about their sex
data_processed_after_exclusions_sex <- data_processed_after_exclusions |>
filter(sex %in% c("f", "m"))
# running the t-test
t.test(IAT_score~sex, data = data_processed_after_exclusions_sex, alternative = "two.sided")
# reporting the t-test
report(t.test(IAT_score~sex, data = data_processed_after_exclusions_sex, alternative = "two.sided"))
# creating the model
model_a <- lm(IAT_score ~ mean_bfi_a, data = data_processed)
# get summary of the model
summary(model_a)
# reporting the model
report(model_a)
# creating the model
model_c <- lm(IAT_score ~ mean_bfi_c, data = data_processed)
# get summary of the model
summary(model_c)
# reporting the model
report(model_c)
# creating the model
model_e <- lm(IAT_score ~ mean_bfi_e, data = data_processed)
# get summary of the model
summary(model_e)
# reporting the model
report(model_e)
# creating the model
model_n <- lm(IAT_score ~ mean_bfi_n, data = data_processed)
# get summary of the model
summary(model_n)
# reporting the model
report(model_n)
# creating the model
model_o <- lm(IAT_score ~ mean_bfi_o, data = data_processed)
# get summary of the model
summary(model_o)
# reporting the model
report(model_o)
# first lets make a new column defining if the IAT score is an extreme score or not
IAT_top_10_percentile_threshold <- quantile(data_processed_after_exclusions$IAT_score, 0.9, na.rm = TRUE)
IAT_bottom_10_percentile_threshold <- quantile(data_processed_after_exclusions$IAT_score, 0.1, na.rm = TRUE)
data_processed_after_exclusions_extreme_IAT <-
data_processed_after_exclusions |>
mutate(extreme_IAT = ifelse(IAT_score >= IAT_top_10_percentile_threshold | IAT_score <= IAT_bottom_10_percentile_threshold,
"extreme",
"normal"))
# lets define a function for making the plots
function_plot_BFI_IAT <- function(column, name_subscale){
ggplot(data_processed_after_exclusions_extreme_IAT, # define which data frame should be used
aes(x = get(column), y = IAT_score)) + # define which variable is on the x and which is on the y axis
geom_point(alpha = 0.7, # turning down alpha a bit so you can see where are more points and where are less
aes(shape = extreme_IAT)) + # using different shapes based on extremeness of IAT score
scale_shape_manual(values = c(17, 16)) + # defining which shapes should be used
geom_smooth(method = "lm") + # add regression line
ggtitle(name_subscale)+ # add title for the whole plot
xlab(paste0("Mean ", name_subscale))+ # add label for x axis
ylab("IAT Score")+ # add label for y axis
theme_classic() + # give plot a classic theme
theme(plot.title = element_text(hjust = 0.5),  # Center the title horizontally
legend.position = "none")  # remove the legend
}
# defining all the plots
p_a <- function_plot_BFI_IAT("mean_bfi_a", "Agreeableness")
p_c <- function_plot_BFI_IAT("mean_bfi_c", "Conscientiousness")
p_e <- function_plot_BFI_IAT("mean_bfi_e", "Extraversion")
p_n <- function_plot_BFI_IAT("mean_bfi_n", "Neuroticism")
p_o <- function_plot_BFI_IAT("mean_bfi_o", "Openness")
# combine all plots into one
combined_plot <- p_a + p_c + p_e + p_n + p_o
print(combined_plot)
# save the combined plot
ggsave("../communications/combined_plot.png", width = 20, plot = combined_plot, dpi = 300, device = "png")
ggsave("../communications/combined_plot.pdf", width = 20, plot = combined_plot, dpi = 300, device = "pdf")
sessionInfo()
# set knit options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
library(ggdist)
library(ggrain)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
library(ggExtra)
library(patchwork)
library(ggrepel)
library(remotes)
library(ggmagnify)
library(report)
library(psych)
data_processed <- read_csv("../data/processed/data_processed.csv")
data_processed_after_exclusions <- data_processed |>
filter(exclusion == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
group_by(sex) |>
summarise(n = n()) |>
mutate(
sex = recode(sex, "f" = "female", "m" = "male"),
Percent = paste0(round_half_up((n / sum(n)) * 100, 1), "%")
) |>
rename(Sex = sex) |>
kable() |>
kable_classic(full_width = FALSE)
proportion_available_age <-
(sum(data_processed_after_exclusions$age != "other/missing/error") / nrow(data_processed_after_exclusions)) |>
round(3)
proportion_available_sex <-
(sum(data_processed_after_exclusions$sex %in% c("f", "m")) / nrow(data_processed_after_exclusions)) |>
round(3)
print(paste0("Variable age was available for ", proportion_available_age, " of participants and variable sex for ",
proportion_available_sex, " of participants."))
# defining a function to get all columns of one subscale in a vector
function_items_subscale_bfi <- function(subscale, n){
items_subscale_bfi <- c()
for (i in 1:n){
items_subscale_bfi <- append(items_subscale_bfi, paste0("bfi_", subscale, i))
}
items_subscale_bfi
}
# agreeableness
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("a", 9)), check.keys =TRUE)
# conscientiousness
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("c", 9)), check.keys =TRUE)
# extraversion
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("e", 8)), check.keys =TRUE)
# neuroticism
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("n", 8)), check.keys =TRUE)
# openness
alpha(subset(data_processed_after_exclusions,
select = function_items_subscale_bfi("o", 10)), check.keys =TRUE)
# defining a function for the histograms for the BFI subscales
histogram_bfi_subscales <- function(column, x_label){
ggplot(data_processed_after_exclusions, aes(x = get(column))) +
geom_histogram(binwidth = 0.1,
boundary = 0,
fill = viridis_pal(begin = 0.45, option = "mako")(1),
color = viridis_pal(begin = 0.30, option = "mako")(1)) +
xlab(x_label) +
ylab("Frequency") +
coord_cartesian(xlim = c(1,6))+
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 10))+
theme_minimal()
}
histogram_bfi_subscales("mean_bfi_a", "Mean Agreeableness")
histogram_bfi_subscales("mean_bfi_c", "Mean Conscientiousness")
histogram_bfi_subscales("mean_bfi_e", "Mean Extraversion")
histogram_bfi_subscales("mean_bfi_n", "Mean Neuroticism")
histogram_bfi_subscales("mean_bfi_o", "Mean Openness")
ggplot(data_processed_after_exclusions, aes(x = IAT_score)) +
geom_histogram(binwidth = 0.05,
boundary = 0,
fill = viridis_pal(begin = 0.45, option = "mako")(1),
color = viridis_pal(begin = 0.30, option = "mako")(1)) +
xlab("IAT Score") +
ylab("Frequency") +
coord_cartesian(xlim = c(-2,2))+
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 10))+
theme_minimal()
# making a new data frame with only the columnes required for the correlatio matrix
data_processed_cols_correlation <- data_processed_after_exclusions |>
select(c(mean_bfi_a, mean_bfi_c, mean_bfi_e, mean_bfi_n, mean_bfi_o, IAT_score))
# making the correlation matrix
cor(data_processed_cols_correlation, use = "pairwise.complete.obs", method="pearson") |>
round(2)
# to run this test I'm creating a data frame with only the subjects that gave information about their sex
data_processed_after_exclusions_sex <- data_processed_after_exclusions |>
filter(sex %in% c("f", "m"))
# running the t-test
t.test(IAT_score~sex, data = data_processed_after_exclusions_sex, alternative = "two.sided")
# reporting the t-test
report(t.test(IAT_score~sex, data = data_processed_after_exclusions_sex, alternative = "two.sided"))
# creating the model
model_a <- lm(IAT_score ~ mean_bfi_a, data = data_processed_after_exclusions)
# get summary of the model
summary(model_a)
# reporting the model
report(model_a)
# creating the model
model_c <- lm(IAT_score ~ mean_bfi_c, data = data_processed_after_exclusions)
# get summary of the model
summary(model_c)
# reporting the model
report(model_c)
# creating the model
model_e <- lm(IAT_score ~ mean_bfi_e, data = data_processed_after_exclusions)
# get summary of the model
summary(model_e)
# reporting the model
report(model_e)
# creating the model
model_n <- lm(IAT_score ~ mean_bfi_n, data = data_processed_after_exclusions)
# get summary of the model
summary(model_n)
# reporting the model
report(model_n)
# creating the model
model_o <- lm(IAT_score ~ mean_bfi_o, data = data_processed_after_exclusions)
# get summary of the model
summary(model_o)
# reporting the model
report(model_o)
# first lets make a new column defining if the IAT score is an extreme score or not
IAT_top_10_percentile_threshold <- quantile(data_processed_after_exclusions$IAT_score, 0.9, na.rm = TRUE)
IAT_bottom_10_percentile_threshold <- quantile(data_processed_after_exclusions$IAT_score, 0.1, na.rm = TRUE)
data_processed_after_exclusions_extreme_IAT <-
data_processed_after_exclusions |>
mutate(extreme_IAT = ifelse(IAT_score >= IAT_top_10_percentile_threshold | IAT_score <= IAT_bottom_10_percentile_threshold,
"extreme",
"normal"))
# lets define a function for making the plots
function_plot_BFI_IAT <- function(column, name_subscale){
ggplot(data_processed_after_exclusions_extreme_IAT, # define which data frame should be used
aes(x = get(column), y = IAT_score)) + # define which variable is on the x and which is on the y axis
geom_point(alpha = 0.7, # turning down alpha a bit so you can see where are more points and where are less
aes(shape = extreme_IAT)) + # using different shapes based on extremeness of IAT score
scale_shape_manual(values = c(17, 16)) + # defining which shapes should be used
geom_smooth(method = "lm") + # add regression line
ggtitle(name_subscale)+ # add title for the whole plot
xlab(paste0("Mean ", name_subscale))+ # add label for x axis
ylab("IAT Score")+ # add label for y axis
theme_classic() + # give plot a classic theme
theme(plot.title = element_text(hjust = 0.5),  # Center the title horizontally
legend.position = "none")  # remove the legend
}
# defining all the plots
p_a <- function_plot_BFI_IAT("mean_bfi_a", "Agreeableness")
p_c <- function_plot_BFI_IAT("mean_bfi_c", "Conscientiousness")
p_e <- function_plot_BFI_IAT("mean_bfi_e", "Extraversion")
p_n <- function_plot_BFI_IAT("mean_bfi_n", "Neuroticism")
p_o <- function_plot_BFI_IAT("mean_bfi_o", "Openness")
# combine all plots into one
combined_plot <- p_a + p_c + p_e + p_n + p_o
print(combined_plot)
# save the combined plot
ggsave("../communications/combined_plot.png", width = 20, plot = combined_plot, dpi = 300, device = "png")
ggsave("../communications/combined_plot.pdf", width = 20, plot = combined_plot, dpi = 300, device = "pdf")
sessionInfo()
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(readr)
library(ggrain)
# Set seed for reproducibility
set.seed(123)
# defining how many rows
n_rows <- 100
# generating random values for a few columns
gender <- sample(c("male", "female"), n_rows, replace = TRUE)
relationship <- sample(c("yes", "no"), n_rows, replace = TRUE)
extraversion <- rnorm(n_rows, mean = 3, sd = 1) |>
round(1) |>
pmin(5) |>
pmax(1)
# creating the data frame
sim_data <- data.frame(gender, relationship, extraversion)
# show the first few rows of the dataset
head(sim_data)
# save the dataset
dir.create("data")
write_csv(sim_data, "data/sim_data.csv")
# reloading the dataset
sim_data <- read.csv("data/sim_data.csv")
p_good <- ggplot(sim_data, aes(x = gender, y = extraversion, fill = gender)) +
geom_rain(
point.args = list(alpha = 0.5)
) +
labs(title = "Extraversion Score by Gender",
x = "Gender",
y = "Extraversion Score") +
theme_classic()+
scale_y_continuous(
breaks = seq(1, 5, 1),
limits = c(1,5)
) +
theme(legend.position = "none")
p_good
p_bad <- ggplot(sim_data, aes(x = extraversion, fill = gender)) +
geom_histogram(binwidth = 0.25, position = "identity", alpha = 0.7) +
scale_fill_manual(values = c("darkred", "forestgreen")) +
labs(title = "Extraversion Scores by Gender",
x = "Extraversion Score", y = "Frequency") +
theme_minimal()
p_bad
dir.create("plots/")
ggsave("plots/plot_good_sarahschnyder.pdf", p_good, width = 8, height = 6)
ggsave("plots/plot_bad_sarahschnyder.pdf", p_bad, width = 8, height = 6)
sessionInfo()
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(readr)
library(ggrain)
# Set seed for reproducibility
set.seed(123)
# defining how many rows
n_rows <- 100
# generating random values for a few columns
gender <- sample(c("male", "female"), n_rows, replace = TRUE)
extraversion <- rnorm(n_rows, mean = 3, sd = 1) |>
round(1) |>
pmin(5) |>
pmax(1)
# creating the data frame
sim_data <- data.frame(gender, extraversion)
# show the first few rows of the dataset
head(sim_data)
# save the dataset
dir.create("data")
write_csv(sim_data, "data/sim_data.csv")
# reloading the dataset
sim_data <- read.csv("data/sim_data.csv")
p_good <- ggplot(sim_data, aes(x = gender, y = extraversion, fill = gender)) +
geom_rain(
point.args = list(alpha = 0.5)
) +
labs(title = "Extraversion Score by Gender",
x = "Gender",
y = "Extraversion Score") +
theme_classic()+
scale_y_continuous(
breaks = seq(1, 5, 1),
limits = c(1,5)
) +
theme(legend.position = "none")
p_good
p_bad <- ggplot(sim_data, aes(x = extraversion, fill = gender)) +
geom_histogram(binwidth = 0.25, position = "identity", alpha = 0.7) +
scale_fill_manual(values = c("darkred", "forestgreen")) +
labs(title = "Extraversion Scores by Gender",
x = "Extraversion Score", y = "Frequency") +
theme_minimal()
p_bad
dir.create("plots/")
ggsave("plots/plot_good_sarahschnyder.pdf", p_good, width = 8, height = 6)
ggsave("plots/plot_bad_sarahschnyder.pdf", p_bad, width = 8, height = 6)
sessionInfo()
